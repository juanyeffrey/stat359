{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c553cd3",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Bonus: Finding Semantic Directions\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b073f",
   "metadata": {},
   "source": [
    "## Discovering Semantic Directions\n",
    "\n",
    "Can I find the directional representation of an abstract concepts \"evil\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36574269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe822a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FastText embeddings\n",
    "embeddings = KeyedVectors.load('fasttext-wiki-news-subwords-300.model', mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bbe13",
   "metadata": {},
   "source": [
    "## Finding Semantic Directions\n",
    "\n",
    "We'll compute directions by averaging multiple word pair differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59e3a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_direction(word_pairs, embeddings):\n",
    "    directions = []\n",
    "    for w1, w2 in word_pairs:\n",
    "        if w1 in embeddings and w2 in embeddings:\n",
    "            direction = embeddings[w2] - embeddings[w1]\n",
    "            directions.append(direction)\n",
    "    if not directions:\n",
    "        return None\n",
    "    avg_direction = np.mean(directions, axis=0)\n",
    "    return avg_direction / np.linalg.norm(avg_direction)  \n",
    "\n",
    "def apply_direction(word, direction, embeddings, top_n=5):\n",
    "    if word not in embeddings:\n",
    "        return []\n",
    "    result_vec = embeddings[word] + direction\n",
    "    similar = embeddings.similar_by_vector(result_vec, topn=top_n + 1)\n",
    "    return [(w, s) for w, s in similar if w != word][:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c2e1b",
   "metadata": {},
   "source": [
    "## The \"Evil/Corruption\" Direction\n",
    "\n",
    "Find the mathematical direction that transforms good/neutral concepts into evil/corrupted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9bda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher: ex-teacher (similarity: 0.481)\n",
      "Other versions: schoolmate, tormentor\n",
      "\n",
      "scientist: pseudo-scientist (similarity: 0.524)\n",
      "Other versions: mad-scientist, pseudoscientist\n",
      "\n",
      "leader: leader- (similarity: 0.538)\n",
      "Other versions: co-leader, sub-leader\n",
      "\n",
      "wizard: sorcerer (similarity: 0.566)\n",
      "Other versions: warlock, wizards\n",
      "\n",
      "knight: knight-errant (similarity: 0.536)\n",
      "Other versions: marauder, goblin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rairs that represent \"evil/corruption\" transformation\n",
    "evil_pairs = [\n",
    "    ('knight', 'warlord'),\n",
    "    ('wizard', 'sorcerer'),\n",
    "    ('priest', 'cultist'),\n",
    "    ('medicine', 'poison'),\n",
    "    ('truth', 'propaganda'),\n",
    "    ('justice', 'revenge'),\n",
    "    ('law', 'tyranny'),\n",
    "    ('virtue', 'vice'),\n",
    "    ('loyalty', 'betrayal'),\n",
    "]\n",
    "\n",
    "# Find the \"evil\" direction\n",
    "evil_dir = find_direction(evil_pairs, embeddings)\n",
    "\n",
    "# Test the direction on new words\n",
    "test_words = ['teacher', 'scientist', 'leader', 'wizard', 'knight']\n",
    "for word in test_words:\n",
    "    results = apply_direction(word, evil_dir, embeddings, top_n=3)\n",
    "    if results:\n",
    "        print(f\"{word:5}: {results[0][0]} (similarity: {results[0][1]:.3f})\")\n",
    "        print(f\"Other versions: {', '.join([w for w, s in results[1:]])}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6673a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10707768\n"
     ]
    }
   ],
   "source": [
    "evil_word_vec = embeddings['evil']\n",
    "evil_word_normalized = evil_word_vec / np.linalg.norm(evil_word_vec)\n",
    "similarity = cosine_similarity([evil_dir], [evil_word_normalized])[0][0]\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23243c3c",
   "metadata": {},
   "source": [
    "I attempted to find an \"eigenvector\" for the concept of evil. This idea that abstract concepts like \"evil\" and \"corruption\" can be represented as directions in embedding space is based of the fact that words that appear in similar contexts have similar meanings. Word embeddings are learned so that semantic relationships are encoded as geometric patterns When a model is trained, the model will be made such that certain word transformations consistently appear in the same direction. For example \"knight\" and \"warlord\" both appear in military contexts, but \"warlord\" co-occurs more frequently with words like \"brutal,\" \"conquest,\" and \"tyranny\". Similarly \"medicine\" and \"poison\" both relate to health, but \"poison\" appears near \"deadly,\" \"toxic,\" and \"harmful\". The model learns these contextual associations in the embedding space, just like \"king - man + woman â‰ˆ queen\" gender is encoded as a consistent direction. \n",
    "\n",
    "I tried to extracted is a representation for evil or corruction by averaging 9 word pair differences. Despite using diverse, non-related pairs, the model found a direction that was applicable to unseen words. Applying this direction new words produces their corrupted versions, showing the learned direction captures the intended semantic shift. For example:\n",
    "\n",
    "     Teacher trasnforms to \"tormentor\"\n",
    "     Scientist transforms to \"mad-scientist\"\n",
    "     Wizard transforms to \"warlock\"\n",
    "\n",
    "This shows that the embeddings for the concept of evil encode more than just semantic meaning but also ethical moral associations, making abstract concepts like \"corruption\" navigable through vector math. We see that the conceptal representation of evil learned from the word pairs, isn't actually very similar to the embeddings of the word \"evil\". This reveals a distinction about the word \"evil\" as a static noun or adjective, and our learned direction representing a transformation of corruption. The corruption direction I found encodes the change from good to evil, a dynamic relationship rather than a static one. This lower similarity validates my exploration, were I wasn't trying to find words similar to \"evil,\" but rather find the geometric operation that corrupts concepts, which is a different type of semantic relationship.\n",
    "\n",
    "However, limitations to exist. Often the most logical word wasn't the most similar word, but one of slightly further down the similarity list. Some words, like Leader, also didn't give me the words that I expected like dictator, but it gave other words synonymous with leader. So the quality depends on the training pairs chosen as well as the vocabulary coverage of the embedding model. In the end, this demonstrates that mbeddings capture abstract transformations geometrically, where similar semantic shifts create parallel vectors, enabling us to learn and apply complex operations like \"corruption\" through simple vector math."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcf0c1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat359-su25-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
